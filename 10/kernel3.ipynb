{
  "cells": [
    {
      "metadata": {
        "_uuid": "17c0c62dcc5d8b21b4faa735c3b13d0b0bef9f10"
      },
      "cell_type": "markdown",
      "source": "**Entry-level twitter sentiment analysis implemented using Keras and LSTM**"
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np\n \n# for reproducibility\nfrom numpy.random import seed\nfrom tensorflow import set_random_seed\nrandom_seed = 1\nseed(random_seed)\nrandom_seed += 1\nset_random_seed(random_seed)\nrandom_seed += 1\n\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Embedding, Dropout, SpatialDropout1D\nfrom keras.layers import LSTM, Conv1D, MaxPooling1D\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"../input/\" directory.",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "print('reading CSV')\n\ncsv = pd.read_csv('../input/training.1600000.processed.noemoticon.csv', encoding = \"ISO-8859-1\", header=None)",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "reading CSV\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6b6f4e035644c80a7ae313ea32850d1b58b579fe"
      },
      "cell_type": "code",
      "source": "print('parsing CSV')\n\nX, Y = [], []\n\nfor index, row in csv.iterrows():\n    X.append(row[5])\n    y_part = row[0]\n    if y_part == 0:\n        yy = np.array([0])\n    elif y_part == 4:\n        yy = np.array([1])\n    else:\n        raise Exception('Invalid y_part value=' + y_part)\n    Y.append(yy)",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "parsing CSV\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9f23d92387ca3bf2fdbd96537a1048e26f4d8151"
      },
      "cell_type": "code",
      "source": "print('build words map')\n\nmax_features = 50000\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(X)\nX = tokenizer.texts_to_sequences(X)\nX = pad_sequences(X)\nX, Xt, Y, Yt = train_test_split(X, Y, test_size = 0.3, random_state = random_seed)\n\nvalidation_size = 1500\nX_validate = Xt[-validation_size:]\nY_validate = Yt[-validation_size:]\nXt = Xt[:-validation_size]\nYt = Yt[:-validation_size]\n\nmaxlen = 0\ndef wrap_array(x, maxlen):\n    for index in range(len(x)):\n        xx = x[index]\n        if len(xx) > maxlen:\n            maxlen = len(xx)\n        x[index] = np.array(xx)\n    return np.array(x), maxlen\n\nX, maxlen = wrap_array(X, maxlen)\nXt, maxlen = wrap_array(Xt, maxlen)\nX_validate, maxlen = wrap_array(X_validate, maxlen)\nY, maxlen = wrap_array(Y, maxlen)\nYt, maxlen = wrap_array(Yt, maxlen)\nY_validate, maxlen = wrap_array(Y_validate, maxlen)",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "build words map\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "919bdd957780d5ca32d1644588cd71e64cc4e297"
      },
      "cell_type": "code",
      "source": "print('build model')\n\nbatch_size = 256\n\nmodel = Sequential()\nmodel.add(Embedding(max_features, 128, input_length=maxlen))\nmodel.add(SpatialDropout1D(0.2))\nmodel.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(LSTM(124, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='nadam',\n              metrics=['accuracy'])\nprint(model.summary())\n\nprint('Train...')\nmodel.fit(X, Y, batch_size=batch_size, epochs=2, validation_data=(Xt, Yt), verbose=2)\n\nscore, acc = model.evaluate(X_validate, Y_validate, batch_size=batch_size)\nprint('Test score:', score)\nprint('Test accuracy:', acc)",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "build model\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_3 (Embedding)      (None, 118, 128)          6400000   \n_________________________________________________________________\nspatial_dropout1d_3 (Spatial (None, 118, 128)          0         \n_________________________________________________________________\nconv1d_3 (Conv1D)            (None, 118, 32)           12320     \n_________________________________________________________________\nmax_pooling1d_3 (MaxPooling1 (None, 59, 32)            0         \n_________________________________________________________________\nlstm_3 (LSTM)                (None, 124)               77872     \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 125       \n_________________________________________________________________\nactivation_3 (Activation)    (None, 1)                 0         \n=================================================================\nTotal params: 6,490,317\nTrainable params: 6,490,317\nNon-trainable params: 0\n_________________________________________________________________\nNone\nTrain...\nTrain on 1120000 samples, validate on 478500 samples\nEpoch 1/2\n - 825s - loss: 0.4184 - acc: 0.8074 - val_loss: 0.3865 - val_acc: 0.8252\nEpoch 2/2\n - 802s - loss: 0.3660 - acc: 0.8369 - val_loss: 0.3825 - val_acc: 0.8286\n1500/1500 [==============================] - 1s 355us/step\nTest score: 0.37005156779289244\nTest accuracy: 0.8326666690508524\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d80fde67cae3fe3919a22753ae2f951f33267cbe"
      },
      "cell_type": "code",
      "source": "print('Trying to predict:')\ntext = \"This is a presidential decree that Rada's defence committee approved and suggested MPs to support. As some MPs write, there is no agreement on a restriction of certain freedoms(frdm of assembly among them). They also want it written down that elections will take place on March 31\"\nprint(text)\ntokens = tokenizer.texts_to_sequences([text])\ntokens = pad_sequences(tokens, maxlen=maxlen)\nsentiment = model.predict(np.array(tokens), batch_size=1, verbose = 2)[0][0]\nprint()\nprint('Sentiment =', sentiment)\nif (round(sentiment) == 0):\n    print('Negative')\nelse:\n    print('Positive')",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Trying to predict:\nThis is a presidential decree that Rada's defence committee approved and suggested MPs to support. As some MPs write, there is no agreement on a restriction of certain freedoms(frdm of assembly among them). They also want it written down that elections will take place on March 31\n\nSentiment = 0.7017813\nPositive\n",
          "name": "stdout"
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}