{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTroch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.]) <class 'torch.Tensor'> False\n",
      "tensor([10.]) <class 'torch.Tensor'> False\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.])\n",
    "y = torch.tensor([10.])\n",
    "\n",
    "print(x, type(x), x.requires_grad)\n",
    "print(y, type(y), y.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.], requires_grad=True) <class 'torch.Tensor'> True\n"
     ]
    }
   ],
   "source": [
    "k = torch.tensor([2.], requires_grad=True)\n",
    "\n",
    "print(k, type(k), k.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.], grad_fn=<ThMulBackward>) <class 'torch.Tensor'> True\n"
     ]
    }
   ],
   "source": [
    "y_ = k * x\n",
    "\n",
    "print(y_, type(y_), y_.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([64.], grad_fn=<PowBackward0>) <class 'torch.Tensor'> True\n"
     ]
    }
   ],
   "source": [
    "loss = (y - y_)**2\n",
    "\n",
    "print(loss, type(loss), loss.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ") <class 'torch.optim.sgd.SGD'>\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD([k,], lr=learning_rate)\n",
    "\n",
    "print(optimizer, type(optimizer)) # Parameter of SGD optimizer -> lr=learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_y_ =  tensor([2.], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([2.], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([64.], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([64.], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([2.], requires_grad=True)\n",
      "last_grad =  None\n",
      "zero_grad =  None\n",
      "step_grad =  tensor([-16.])\n",
      "gradient_descent_value =  tensor([1.6000])\n",
      "predicted_step_key =  tensor([3.6000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([3.6000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([2.], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([3.6000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([64.], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([40.9600], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([3.6000], requires_grad=True)\n",
      "last_grad =  tensor([-16.])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-12.8000])\n",
      "gradient_descent_value =  tensor([1.2800])\n",
      "predicted_step_key =  tensor([4.8800], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([4.8800], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([3.6000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([4.8800], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([40.9600], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([26.2144], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([4.8800], requires_grad=True)\n",
      "last_grad =  tensor([-12.8000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-10.2400])\n",
      "gradient_descent_value =  tensor([1.0240])\n",
      "predicted_step_key =  tensor([5.9040], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([5.9040], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([4.8800], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([5.9040], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([26.2144], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([16.7772], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([5.9040], requires_grad=True)\n",
      "last_grad =  tensor([-10.2400])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-8.1920])\n",
      "gradient_descent_value =  tensor([0.8192])\n",
      "predicted_step_key =  tensor([6.7232], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([6.7232], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([5.9040], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([6.7232], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([16.7772], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([10.7374], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([6.7232], requires_grad=True)\n",
      "last_grad =  tensor([-8.1920])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-6.5536])\n",
      "gradient_descent_value =  tensor([0.6554])\n",
      "predicted_step_key =  tensor([7.3786], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([7.3786], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([6.7232], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([7.3786], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([10.7374], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([6.8719], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([7.3786], requires_grad=True)\n",
      "last_grad =  tensor([-6.5536])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-5.2429])\n",
      "gradient_descent_value =  tensor([0.5243])\n",
      "predicted_step_key =  tensor([7.9028], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([7.9028], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([7.3786], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([7.9028], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([6.8719], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([4.3980], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([7.9028], requires_grad=True)\n",
      "last_grad =  tensor([-5.2429])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-4.1943])\n",
      "gradient_descent_value =  tensor([0.4194])\n",
      "predicted_step_key =  tensor([8.3223], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([8.3223], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([7.9028], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([8.3223], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([4.3980], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([2.8147], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([8.3223], requires_grad=True)\n",
      "last_grad =  tensor([-4.1943])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-3.3554])\n",
      "gradient_descent_value =  tensor([0.3355])\n",
      "predicted_step_key =  tensor([8.6578], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([8.6578], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([8.3223], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([8.6578], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([2.8147], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([1.8014], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([8.6578], requires_grad=True)\n",
      "last_grad =  tensor([-3.3554])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-2.6844])\n",
      "gradient_descent_value =  tensor([0.2684])\n",
      "predicted_step_key =  tensor([8.9263], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([8.9263], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([8.6578], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([8.9263], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([1.8014], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([1.1529], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([8.9263], requires_grad=True)\n",
      "last_grad =  tensor([-2.6844])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-2.1475])\n",
      "gradient_descent_value =  tensor([0.2147])\n",
      "predicted_step_key =  tensor([9.1410], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.1410], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([8.9263], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.1410], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([1.1529], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([0.7379], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.1410], requires_grad=True)\n",
      "last_grad =  tensor([-2.1475])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-1.7180])\n",
      "gradient_descent_value =  tensor([0.1718])\n",
      "predicted_step_key =  tensor([9.3128], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.3128], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.1410], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.3128], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([0.7379], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([0.4722], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.3128], requires_grad=True)\n",
      "last_grad =  tensor([-1.7180])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-1.3744])\n",
      "gradient_descent_value =  tensor([0.1374])\n",
      "predicted_step_key =  tensor([9.4502], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.4502], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.3128], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.4502], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([0.4722], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([0.3022], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.4502], requires_grad=True)\n",
      "last_grad =  tensor([-1.3744])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-1.0995])\n",
      "gradient_descent_value =  tensor([0.1100])\n",
      "predicted_step_key =  tensor([9.5602], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.5602], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.4502], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.5602], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([0.3022], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([0.1934], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.5602], requires_grad=True)\n",
      "last_grad =  tensor([-1.0995])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.8796])\n",
      "gradient_descent_value =  tensor([0.0880])\n",
      "predicted_step_key =  tensor([9.6482], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.6482], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.5602], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.6482], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([0.1934], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([0.1238], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.6482], requires_grad=True)\n",
      "last_grad =  tensor([-0.8796])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.7037])\n",
      "gradient_descent_value =  tensor([0.0704])\n",
      "predicted_step_key =  tensor([9.7185], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.7185], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.6482], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.7185], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([0.1238], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([0.0792], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.7185], requires_grad=True)\n",
      "last_grad =  tensor([-0.7037])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.5629])\n",
      "gradient_descent_value =  tensor([0.0563])\n",
      "predicted_step_key =  tensor([9.7748], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.7748], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.7185], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.7748], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([0.0792], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([0.0507], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.7748], requires_grad=True)\n",
      "last_grad =  tensor([-0.5629])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.4504])\n",
      "gradient_descent_value =  tensor([0.0450])\n",
      "predicted_step_key =  tensor([9.8199], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.8199], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.7748], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.8199], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([0.0507], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([0.0325], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.8199], requires_grad=True)\n",
      "last_grad =  tensor([-0.4504])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.3603])\n",
      "gradient_descent_value =  tensor([0.0360])\n",
      "predicted_step_key =  tensor([9.8559], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.8559], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.8199], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.8559], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([0.0325], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([0.0208], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.8559], requires_grad=True)\n",
      "last_grad =  tensor([-0.3603])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.2882])\n",
      "gradient_descent_value =  tensor([0.0288])\n",
      "predicted_step_key =  tensor([9.8847], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.8847], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.8559], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.8847], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([0.0208], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([0.0133], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.8847], requires_grad=True)\n",
      "last_grad =  tensor([-0.2882])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.2306])\n",
      "gradient_descent_value =  tensor([0.0231])\n",
      "predicted_step_key =  tensor([9.9078], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9078], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.8847], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9078], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([0.0133], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([0.0085], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9078], requires_grad=True)\n",
      "last_grad =  tensor([-0.2306])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.1845])\n",
      "gradient_descent_value =  tensor([0.0184])\n",
      "predicted_step_key =  tensor([9.9262], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9262], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9078], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9262], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([0.0085], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([0.0054], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9262], requires_grad=True)\n",
      "last_grad =  tensor([-0.1845])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.1476])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_descent_value =  tensor([0.0148])\n",
      "predicted_step_key =  tensor([9.9410], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9410], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9262], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9410], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([0.0054], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([0.0035], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9410], requires_grad=True)\n",
      "last_grad =  tensor([-0.1476])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.1181])\n",
      "gradient_descent_value =  tensor([0.0118])\n",
      "predicted_step_key =  tensor([9.9528], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9528], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9410], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9528], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([0.0035], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([0.0022], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9528], requires_grad=True)\n",
      "last_grad =  tensor([-0.1181])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0944])\n",
      "gradient_descent_value =  tensor([0.0094])\n",
      "predicted_step_key =  tensor([9.9622], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9622], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9528], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9622], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([0.0022], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([0.0014], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9622], requires_grad=True)\n",
      "last_grad =  tensor([-0.0944])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0756])\n",
      "gradient_descent_value =  tensor([0.0076])\n",
      "predicted_step_key =  tensor([9.9698], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9698], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9622], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9698], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([0.0014], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([0.0009], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9698], requires_grad=True)\n",
      "last_grad =  tensor([-0.0756])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0604])\n",
      "gradient_descent_value =  tensor([0.0060])\n",
      "predicted_step_key =  tensor([9.9758], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9758], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9698], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9758], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([0.0009], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([0.0006], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9758], requires_grad=True)\n",
      "last_grad =  tensor([-0.0604])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0484])\n",
      "gradient_descent_value =  tensor([0.0048])\n",
      "predicted_step_key =  tensor([9.9807], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9807], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9758], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9807], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([0.0006], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([0.0004], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9807], requires_grad=True)\n",
      "last_grad =  tensor([-0.0484])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0387])\n",
      "gradient_descent_value =  tensor([0.0039])\n",
      "predicted_step_key =  tensor([9.9845], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9845], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9807], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9845], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([0.0004], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([0.0002], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9845], requires_grad=True)\n",
      "last_grad =  tensor([-0.0387])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0309])\n",
      "gradient_descent_value =  tensor([0.0031])\n",
      "predicted_step_key =  tensor([9.9876], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9876], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9845], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9876], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([0.0002], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([0.0002], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9876], requires_grad=True)\n",
      "last_grad =  tensor([-0.0309])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0248])\n",
      "gradient_descent_value =  tensor([0.0025])\n",
      "predicted_step_key =  tensor([9.9901], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9901], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9876], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9901], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([0.0002], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([0.0001], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9901], requires_grad=True)\n",
      "last_grad =  tensor([-0.0248])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0198])\n",
      "gradient_descent_value =  tensor([0.0020])\n",
      "predicted_step_key =  tensor([9.9921], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9921], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9901], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9921], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([0.0001], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([0.0001], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9921], requires_grad=True)\n",
      "last_grad =  tensor([-0.0198])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0158])\n",
      "gradient_descent_value =  tensor([0.0016])\n",
      "predicted_step_key =  tensor([9.9937], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9937], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9921], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9937], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([0.0001], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([0.0000], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9937], requires_grad=True)\n",
      "last_grad =  tensor([-0.0158])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0127])\n",
      "gradient_descent_value =  tensor([0.0013])\n",
      "predicted_step_key =  tensor([9.9949], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9949], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9937], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9949], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([0.0000], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([0.0000], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9949], requires_grad=True)\n",
      "last_grad =  tensor([-0.0127])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0101])\n",
      "gradient_descent_value =  tensor([0.0010])\n",
      "predicted_step_key =  tensor([9.9959], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9959], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9949], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9959], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([0.0000], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([0.0000], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9959], requires_grad=True)\n",
      "last_grad =  tensor([-0.0101])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0081])\n",
      "gradient_descent_value =  tensor([0.0008])\n",
      "predicted_step_key =  tensor([9.9968], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9968], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9959], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9968], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([0.0000], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([0.0000], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9968], requires_grad=True)\n",
      "last_grad =  tensor([-0.0081])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0065])\n",
      "gradient_descent_value =  tensor([0.0006])\n",
      "predicted_step_key =  tensor([9.9974], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9974], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9968], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9974], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([0.0000], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([6.7387e-06], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9974], requires_grad=True)\n",
      "last_grad =  tensor([-0.0065])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0052])\n",
      "gradient_descent_value =  tensor([0.0005])\n",
      "predicted_step_key =  tensor([9.9979], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9979], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9974], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9979], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([6.7387e-06], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([4.3144e-06], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9979], requires_grad=True)\n",
      "last_grad =  tensor([-0.0052])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0042])\n",
      "gradient_descent_value =  tensor([0.0004])\n",
      "predicted_step_key =  tensor([9.9983], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9983], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9979], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9983], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([4.3144e-06], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([2.7599e-06], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9983], requires_grad=True)\n",
      "last_grad =  tensor([-0.0042])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0033])\n",
      "gradient_descent_value =  tensor([0.0003])\n",
      "predicted_step_key =  tensor([9.9987], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9987], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9983], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9987], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([2.7599e-06], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([1.7674e-06], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9987], requires_grad=True)\n",
      "last_grad =  tensor([-0.0033])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0027])\n",
      "gradient_descent_value =  tensor([0.0003])\n",
      "predicted_step_key =  tensor([9.9989], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9989], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9987], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9989], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([1.7674e-06], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([1.1307e-06], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9989], requires_grad=True)\n",
      "last_grad =  tensor([-0.0027])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0021])\n",
      "gradient_descent_value =  tensor([0.0002])\n",
      "predicted_step_key =  tensor([9.9991], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9991], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9989], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9991], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([1.1307e-06], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([7.2365e-07], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9991], requires_grad=True)\n",
      "last_grad =  tensor([-0.0021])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0017])\n",
      "gradient_descent_value =  tensor([0.0002])\n",
      "predicted_step_key =  tensor([9.9993], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9993], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9991], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9993], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([7.2365e-07], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([4.6366e-07], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9993], requires_grad=True)\n",
      "last_grad =  tensor([-0.0017])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0014])\n",
      "gradient_descent_value =  tensor([0.0001])\n",
      "predicted_step_key =  tensor([9.9995], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9995], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9993], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9995], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([4.6366e-07], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([2.9653e-07], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9995], requires_grad=True)\n",
      "last_grad =  tensor([-0.0014])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0011])\n",
      "gradient_descent_value =  tensor([0.0001])\n",
      "predicted_step_key =  tensor([9.9996], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9996], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9995], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9996], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([2.9653e-07], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([1.8995e-07], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9996], requires_grad=True)\n",
      "last_grad =  tensor([-0.0011])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0009])\n",
      "gradient_descent_value =  tensor([0.0001])\n",
      "predicted_step_key =  tensor([9.9997], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9997], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9996], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9997], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([1.8995e-07], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([1.2183e-07], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9997], requires_grad=True)\n",
      "last_grad =  tensor([-0.0009])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0007])\n",
      "gradient_descent_value =  tensor([0.0001])\n",
      "predicted_step_key =  tensor([9.9997], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9997], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9997], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9997], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([1.2183e-07], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([7.8079e-08], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9997], requires_grad=True)\n",
      "last_grad =  tensor([-0.0007])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0006])\n",
      "gradient_descent_value =  tensor([0.0001])\n",
      "predicted_step_key =  tensor([9.9998], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9998], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9997], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9998], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([7.8079e-08], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([4.9800e-08], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9998], requires_grad=True)\n",
      "last_grad =  tensor([-0.0006])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0004])\n",
      "gradient_descent_value =  tensor([0.0000])\n",
      "predicted_step_key =  tensor([9.9998], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9998], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9998], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9998], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([4.9800e-08], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.1804e-08], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9998], requires_grad=True)\n",
      "last_grad =  tensor([-0.0004])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0004])\n",
      "gradient_descent_value =  tensor([0.0000])\n",
      "predicted_step_key =  tensor([9.9999], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9999], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9998], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9999], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.1804e-08], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([2.0464e-08], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9999], requires_grad=True)\n",
      "last_grad =  tensor([-0.0004])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0003])\n",
      "gradient_descent_value =  tensor([0.0000])\n",
      "predicted_step_key =  tensor([9.9999], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9999], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9999], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9999], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([2.0464e-08], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([1.3097e-08], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9999], requires_grad=True)\n",
      "last_grad =  tensor([-0.0003])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0002])\n",
      "gradient_descent_value =  tensor([0.0000])\n",
      "predicted_step_key =  tensor([9.9999], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9999], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9999], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9999], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([1.3097e-08], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([8.3819e-09], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9999], requires_grad=True)\n",
      "last_grad =  tensor([-0.0002])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0002])\n",
      "gradient_descent_value =  tensor([0.0000])\n",
      "predicted_step_key =  tensor([9.9999], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9999], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9999], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9999], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([8.3819e-09], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([5.3924e-09], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9999], requires_grad=True)\n",
      "last_grad =  tensor([-0.0002])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0001])\n",
      "gradient_descent_value =  tensor([0.0000])\n",
      "predicted_step_key =  tensor([9.9999], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([9.9999], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9999], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([9.9999], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([5.3924e-09], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.4961e-09], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([9.9999], requires_grad=True)\n",
      "last_grad =  tensor([-0.0001])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0001])\n",
      "gradient_descent_value =  tensor([0.0000])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([9.9999], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.4961e-09], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([2.2737e-09], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0001])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0001])\n",
      "gradient_descent_value =  tensor([9.5367e-06])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([2.2737e-09], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([1.4552e-09], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0001])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0001])\n",
      "gradient_descent_value =  tensor([7.6294e-06])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([1.4552e-09], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([9.3132e-10], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0001])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0001])\n",
      "gradient_descent_value =  tensor([6.1035e-06])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([9.3132e-10], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([6.1482e-10], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0001])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([4.9591e-06])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([6.1482e-10], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([4.0109e-10], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([4.0054e-06])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([4.0109e-10], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([2.6284e-10], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.2425e-06])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([2.6284e-10], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([1.7826e-10], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([2.6703e-06])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([1.7826e-10], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([1.1005e-10], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([2.0981e-06])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([1.1005e-10], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([7.3669e-11], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([1.7166e-06])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([7.3669e-11], grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step_loss =  tensor([4.4565e-11], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([1.3351e-06])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([4.4565e-11], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.2742e-11], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([1.1444e-06])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.2742e-11], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([2.2737e-11], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([9.5367e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([2.2737e-11], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([1.4552e-11], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([7.6294e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([1.4552e-11], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([8.1855e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([5.7220e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([8.1855e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n",
      "last_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "step_y_ =  tensor([10.0000], grad_fn=<ThMulBackward>)\n",
      "last_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "step_loss =  tensor([3.6380e-12], grad_fn=<PowBackward0>)\n",
      "last_k =  tensor([10.0000], requires_grad=True)\n",
      "last_grad =  tensor([-0.0000])\n",
      "zero_grad =  tensor([0.])\n",
      "step_grad =  tensor([-0.0000])\n",
      "gradient_descent_value =  tensor([3.8147e-07])\n",
      "predicted_step_key =  tensor([10.0000], grad_fn=<ThSubBackward>)\n",
      "step_k =  tensor([10.0000], requires_grad=True)\n",
      "____________\n"
     ]
    }
   ],
   "source": [
    "for _ in range(250):\n",
    "    print('last_y_ = ', y_)\n",
    "    y_ = k * x\n",
    "    print('step_y_ = ', y_)\n",
    "\n",
    "    print('last_loss = ', loss)\n",
    "    loss = (y - y_)**2\n",
    "    print('step_loss = ', loss)\n",
    "\n",
    "    print('last_k = ', k)\n",
    "    print('last_grad = ', k.grad) # here starts The Loop # first time no .grad\n",
    "    optimizer.zero_grad() # clean all grad\n",
    "    print('zero_grad = ', k.grad)\n",
    "    loss.backward() # ~backprob~ step\n",
    "    print('step_grad = ', k.grad)\n",
    "    print('gradient_descent_value = ', -learning_rate*k.grad)\n",
    "    print('predicted_step_key = ', k - learning_rate*k.grad)\n",
    "\n",
    "    optimizer.step()\n",
    "    print('step_k = ', k)\n",
    "    print('____________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.]) <class 'torch.Tensor'> False\n",
      "tensor([3.]) <class 'torch.Tensor'> False\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.tensor([2.])\n",
    "x2 = torch.tensor([3.])\n",
    "\n",
    "print(x1, type(x1), x1.requires_grad)\n",
    "print(x2, type(x2), x2.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1200], requires_grad=True) <class 'torch.Tensor'> True\n"
     ]
    }
   ],
   "source": [
    "k1 = torch.tensor([.12], requires_grad=True)\n",
    "k2 = torch.tensor([.18], requires_grad=True)\n",
    "\n",
    "print(k1, type(k1), k1.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7800], grad_fn=<ThAddBackward>) <class 'torch.Tensor'> True\n"
     ]
    }
   ],
   "source": [
    "res = k1*x1 + k2*x2\n",
    "\n",
    "print(res, type(res), res.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = res**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ") <class 'torch.optim.sgd.SGD'>\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD([k1, k2], lr=learning_rate)\n",
    "\n",
    "print(optimizer, type(optimizer)) # Parameter of SGD optimizer -> lr=learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0\n",
      "res =  tensor([0.7800], grad_fn=<ThAddBackward>)\n",
      "step_loss tensor([0.6084], grad_fn=<PowBackward0>)\n",
      "step_grad =  tensor([3.1200]) tensor([4.6800])\n",
      "step_k =  tensor([0.0888], requires_grad=True) tensor([0.1332], requires_grad=True)\n",
      "____________\n",
      "step =  50\n",
      "res =  tensor([2.2578e-07], grad_fn=<ThAddBackward>)\n",
      "step_loss tensor([5.0975e-14], grad_fn=<PowBackward0>)\n",
      "step_grad =  tensor([9.0311e-07]) tensor([1.3547e-06])\n",
      "step_k =  tensor([2.3979e-08], requires_grad=True) tensor([3.9706e-08], requires_grad=True)\n",
      "____________\n",
      "step =  100\n",
      "res =  tensor([6.5281e-14], grad_fn=<ThAddBackward>)\n",
      "step_loss tensor([4.2616e-27], grad_fn=<PowBackward0>)\n",
      "step_grad =  tensor([2.6112e-13]) tensor([3.9169e-13])\n",
      "step_k =  tensor([-0.0000], requires_grad=True) tensor([1.1501e-09], requires_grad=True)\n",
      "____________\n",
      "step =  150\n",
      "res =  tensor([8.8818e-16], grad_fn=<ThAddBackward>)\n",
      "step_loss tensor([7.8886e-31], grad_fn=<PowBackward0>)\n",
      "step_grad =  tensor([3.5527e-15]) tensor([5.3291e-15])\n",
      "step_k =  tensor([-0.0000], requires_grad=True) tensor([1.1501e-09], requires_grad=True)\n",
      "____________\n",
      "step =  200\n",
      "res =  tensor([8.8818e-16], grad_fn=<ThAddBackward>)\n",
      "step_loss tensor([7.8886e-31], grad_fn=<PowBackward0>)\n",
      "step_grad =  tensor([3.5527e-15]) tensor([5.3291e-15])\n",
      "step_k =  tensor([-0.0000], requires_grad=True) tensor([1.1501e-09], requires_grad=True)\n",
      "____________\n",
      "step =  250\n",
      "res =  tensor([8.8818e-16], grad_fn=<ThAddBackward>)\n",
      "step_loss tensor([7.8886e-31], grad_fn=<PowBackward0>)\n",
      "step_grad =  tensor([3.5527e-15]) tensor([5.3291e-15])\n",
      "step_k =  tensor([-0.0000], requires_grad=True) tensor([1.1501e-09], requires_grad=True)\n",
      "____________\n"
     ]
    }
   ],
   "source": [
    "for _ in range(251):\n",
    "    res = k1*x1 + k2*x2\n",
    "    loss = (res - 0)**2\n",
    "    optimizer.zero_grad() # clean all grad\n",
    "    loss.backward() # ~backprob~ step\n",
    "    optimizer.step()\n",
    "    \n",
    "    if _ % 50 == 0:\n",
    "        print('step = ', _)\n",
    "        print('res = ', res)\n",
    "        print('step_loss', loss)\n",
    "        print('step_grad = ', k1.grad, k2.grad)\n",
    "        print('step_k = ', k1, k2)\n",
    "        print('____________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5., 6., 7.]) <class 'torch.Tensor'> False\n",
      "tensor([13., 19., 25., 29., 35., 38., 43.]) <class 'torch.Tensor'> False\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([ 1.,  2.,  3.,  4.,  5., 6., 7.])\n",
    "y = torch.tensor([13., 19., 25., 29., 35., 38., 43.])\n",
    "\n",
    "print(x, type(x), x.requires_grad)\n",
    "print(y, type(y), y.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.], requires_grad=True) <class 'torch.Tensor'> True\n"
     ]
    }
   ],
   "source": [
    "k = torch.tensor([2.], requires_grad=True)\n",
    "b = torch.tensor([0.], requires_grad=True)\n",
    "\n",
    "print(k, type(k), k.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.3337,  4.0846,  5.8355,  6.7109,  7.5864, 11.9636, 12.8391, 14.5900,\n",
      "        16.3409], grad_fn=<ThAddBackward>) <class 'torch.Tensor'> True\n"
     ]
    }
   ],
   "source": [
    "y_ = k*x + b\n",
    "\n",
    "print(y_, type(y_), y_.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  5.4460,  16.6837,  34.0527,  45.0364,  57.5530, 120.2011, 140.1637,\n",
      "        184.6875, 235.3426], grad_fn=<PowBackward0>) <class 'torch.Tensor'> True\n"
     ]
    }
   ],
   "source": [
    "loss_vector = (y_ - y)**2\n",
    "\n",
    "print(loss_vector, type(loss_vector), loss_vector.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2634, grad_fn=<MeanBackward1>) <class 'torch.Tensor'> True <PowBackward0 object at 0x7f3c21945358>\n"
     ]
    }
   ],
   "source": [
    "loss = loss_vector.mean()\n",
    "\n",
    "print(loss, type(loss), loss.requires_grad, loss_vector.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ") <class 'torch.optim.sgd.SGD'>\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD([k, b], lr=learning_rate)\n",
    "\n",
    "print(optimizer, type(optimizer)) # Parameter of SGD optimizer -> lr=learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0\n",
      "res =  tensor([8.8818e-16], grad_fn=<ThAddBackward>)\n",
      "step_loss tensor(470., grad_fn=<MeanBackward1>)\n",
      "step_grad =  tensor([-190.2857])\n",
      "step_k, b =  tensor([3.9029], requires_grad=True) tensor([0.4171], requires_grad=True)\n",
      "____________\n",
      "step =  5000\n",
      "res =  tensor([8.8818e-16], grad_fn=<ThAddBackward>)\n",
      "step_loss tensor(0.6735, grad_fn=<MeanBackward1>)\n",
      "step_grad =  tensor([0.0000])\n",
      "step_k, b =  tensor([4.9286], requires_grad=True) tensor([9.1427], requires_grad=True)\n",
      "____________\n",
      "step =  10000\n",
      "res =  tensor([8.8818e-16], grad_fn=<ThAddBackward>)\n",
      "step_loss tensor(0.6735, grad_fn=<MeanBackward1>)\n",
      "step_grad =  tensor([0.0000])\n",
      "step_k, b =  tensor([4.9286], requires_grad=True) tensor([9.1427], requires_grad=True)\n",
      "____________\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10001):\n",
    "    y_ = k*x + b\n",
    "    loss_vector = (y_ - y)**2\n",
    "    loss = loss_vector.mean()\n",
    "    optimizer.zero_grad() # clean all grad\n",
    "    loss.backward() # ~backprob~ step\n",
    "    optimizer.step()\n",
    "    \n",
    "    if _ % 5000 == 0:\n",
    "        print('step = ', _)\n",
    "        print('res = ', res)\n",
    "        print('step_loss', loss)\n",
    "        print('step_grad = ', k.grad)\n",
    "        print('step_k, b = ', k , b)\n",
    "        print('____________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\"\"\" this function just plotting\n",
    "    your data and linear model \"\"\"\n",
    "def plot_result(X, Y, lin_model=None, extra_point=None):\n",
    "    plt.xlabel('size, m2')\n",
    "    plt.ylabel('price, $1000')\n",
    "    plt.plot(X,Y, 'bo') # 'bo' - means 'b'-blue 'o'-dots, you can use 'ro' or 'gx' ('x' for cross)\n",
    "    if lin_model:\n",
    "        b = lin_model[0]\n",
    "        w = lin_model[1]\n",
    "        t = np.arange(X.min(), X.max(), 0.01)\n",
    "        plt.plot(t, w*t+b , 'k')\n",
    "    if extra_point:\n",
    "        plt.plot(extra_point[0], extra_point[1], 'ro')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_result(np.array(x), np.array(y), [float(b), float(k)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poly Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5., 6., 7.]) <class 'torch.Tensor'> False\n",
      "tensor([13., 19., 25., 29., 35., 38., 43.]) <class 'torch.Tensor'> False\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([ 1.,  2.,  3.,  4.,  5., 6., 7.])\n",
    "y = torch.tensor([13., 19., 25., 29., 35., 38., 43.])\n",
    "\n",
    "print(x, type(x), x.requires_grad)\n",
    "print(y, type(y), y.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7561], requires_grad=True) <class 'torch.Tensor'> True\n",
      "tensor([-0.7958], requires_grad=True) <class 'torch.Tensor'> True\n",
      "tensor([-0.2491], requires_grad=True) <class 'torch.Tensor'> True\n"
     ]
    }
   ],
   "source": [
    "w0 = torch.randn(1 , requires_grad=True)\n",
    "w1 = torch.randn(1 , requires_grad=True)\n",
    "w2 =torch.randn(1 , requires_grad=True)\n",
    "\n",
    "\n",
    "print(w0, type(w0), w0.requires_grad)\n",
    "print(w1, type(w1), w1.requires_grad)\n",
    "print(w2, type(w2), w2.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -0.2888,  -1.8320,  -3.8734,  -6.4130,  -9.4508, -12.9868, -17.0210],\n",
       "       grad_fn=<ThAddBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ = w0 + w1*x + w2*x**2\n",
    "y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 176.5930,  433.9720,  833.6717, 1254.0780, 1975.8711, 2599.6531,\n",
      "        3602.5237], grad_fn=<PowBackward0>) <class 'torch.Tensor'> True\n"
     ]
    }
   ],
   "source": [
    "loss_vector = (y_ - y)**2\n",
    "\n",
    "print(loss_vector, type(loss_vector), loss_vector.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1553.7660, grad_fn=<MeanBackward1>) <class 'torch.Tensor'> True\n"
     ]
    }
   ],
   "source": [
    "loss = loss_vector.mean()\n",
    "\n",
    "print(loss, type(loss), loss.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.001\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ") <class 'torch.optim.sgd.SGD'>\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.SGD([w0, w1, w2], lr=learning_rate)\n",
    "\n",
    "print(optimizer, type(optimizer)) # Parameter of SGD optimizer -> lr=learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0\n",
      "res =  tensor([ -0.2888,  -1.8320,  -3.8734,  -6.4130,  -9.4508, -12.9868, -17.0210],\n",
      "       grad_fn=<ThAddBackward>)\n",
      "step_loss tensor(1553.7660, grad_fn=<MeanBackward1>)\n",
      "step_grad =  tensor([-72.5331])\n",
      "step_k, b =  tensor([0.8287], requires_grad=True) tensor([-0.4440], requires_grad=True) tensor([1.6969], requires_grad=True)\n",
      "____________\n",
      "step =  5000\n",
      "res =  tensor([12.5925, 18.8470, 24.5924, 29.8287, 34.5558, 38.7738, 42.4827],\n",
      "       grad_fn=<ThAddBackward>)\n",
      "step_loss tensor(0.3009, grad_fn=<MeanBackward1>)\n",
      "step_grad =  tensor([-0.0934])\n",
      "step_k, b =  tensor([5.8289], requires_grad=True) tensor([7.0182], requires_grad=True) tensor([-0.2546], requires_grad=True)\n",
      "____________\n",
      "step =  10000\n",
      "res =  tensor([12.7847, 18.9029, 24.5587, 29.7522, 34.4833, 38.7521, 42.5586],\n",
      "       grad_fn=<ThAddBackward>)\n",
      "step_loss tensor(0.2634, grad_fn=<MeanBackward1>)\n",
      "step_grad =  tensor([-0.0593])\n",
      "step_k, b =  tensor([6.2043], requires_grad=True) tensor([6.8116], requires_grad=True) tensor([-0.2312], requires_grad=True)\n",
      "____________\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10001):\n",
    "    y_ = w0 + w1*x + w2*x**2\n",
    "    loss_vector = (y_ - y)**2\n",
    "    loss = loss_vector.mean()\n",
    "    optimizer.zero_grad() # clean all grad\n",
    "    loss.backward() # ~backprob~ step\n",
    "    optimizer.step()\n",
    "    \n",
    "    if _ % 5000 == 0:\n",
    "        print('step = ', _)\n",
    "        print('res = ', y_)\n",
    "        print('step_loss', loss)\n",
    "        print('step_grad = ', w0.grad)\n",
    "        print('step_k, b = ', w0 , w1, w2)\n",
    "        print('____________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\"\"\" this function just plotting\n",
    "    your data and linear model \"\"\"\n",
    "def plot_result(X, Y, poly_model=None, extra_point=None):\n",
    "    plt.xlabel('size, m2')\n",
    "    plt.ylabel('price, $1000')\n",
    "    plt.plot(X,Y, 'bo') # 'bo' - means 'b'-blue 'o'-dots, you can use 'ro' or 'gx' ('x' for cross)\n",
    "    if poly_model:\n",
    "        w0 = poly_model[0]\n",
    "        w1 = poly_model[1]\n",
    "        w2 = poly_model[2]\n",
    "        t = np.arange(X.min(), X.max(), 0.01)\n",
    "        plt.plot(t, w0+w1*t+w2*t**2 , 'k')\n",
    "    if extra_point:\n",
    "        plt.plot(extra_point[0], extra_point[1], 'ro')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_result(np.array(x), np.array(y), [float(w0), float(w1), float(w2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cea89e0bc18a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;36m28.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30.\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m32.\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m33.\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m34.\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m39.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m42.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m44.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;36m0.\u001b[0m \u001b[0;34m,\u001b[0m  \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([ 28., 30.,  32.,  33.,  34.,  39., 40., 42., 44.])\n",
    "y = torch.tensor([ 0.,   0. ,  0.,   0.,   0.,   1.,  1.,  1.,  1.])\n",
    "\n",
    "x = (x - x.mean())/x.std()\n",
    "\n",
    "print(x, type(x), x.requires_grad)\n",
    "print(y, type(y), y.requires_grad)\n",
    "\n",
    "w0 = torch.randn(1 , requires_grad=True)\n",
    "w1 = torch.randn(1 , requires_grad=True)\n",
    "for _ in range(20001):\n",
    "    y_ = w0 + w1*x\n",
    "    loss_vector = (y_ - y)**2\n",
    "    loss = loss_vector.mean()\n",
    "    optimizer.zero_grad() # clean all grad\n",
    "    loss.backward() # ~backprob~ step\n",
    "    optimizer.step()\n",
    "    \n",
    "    if _ % 5000 == 0:\n",
    "        print('step = ', _)\n",
    "        print('res = ', y_)\n",
    "        print('step_loss', loss)\n",
    "        print('step_grad = ', w0.grad)\n",
    "        print('step_k, b = ', w0 , w1)\n",
    "        print('____________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\"\"\" this function just plotting\n",
    "    your data and linear model \"\"\"\n",
    "def plot_result(X, Y, lin_model=None, extra_point=None):\n",
    "    plt.xlabel('size, mm2')\n",
    "    plt.ylabel('vbs, 0 or 1')\n",
    "    plt.plot([v[0] for v in zip(X,Y) if v[1] == 0.], [v[1] for v in zip(X,Y) if v[1] == 0.], 'bo',\n",
    "             [v[0] for v in zip(X,Y) if v[1] == 1.], [v[1] for v in zip(X,Y) if v[1] == 1.], 'ro',) # 'bo' - means 'b'-blue 'o'-dots, you can use 'ro' or 'gx' ('x' for cross)\n",
    "    if lin_model:\n",
    "        b = lin_model[0]\n",
    "        w = lin_model[1]\n",
    "        t = np.arange(X.min(), X.max(), 0.01)\n",
    "        plt.plot(t, 1/(1 + np.exp(- w*t+b)) , 'k')\n",
    "    if extra_point:\n",
    "        plt.plot(extra_point[0], extra_point[1], 'ro')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-538461f548e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_result' is not defined"
     ]
    }
   ],
   "source": [
    "plot_result(np.array(x), np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
