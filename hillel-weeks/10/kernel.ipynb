{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np\nnp.random.seed(1337)  # for reproducibility\n\nfrom collections import Counter\n\nfrom keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Embedding, Dropout\nfrom keras.layers import LSTM\n\n# Input data files are available in the \"../input/\" directory.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "print('reading CSV')\n\nX, Y, Xt, Yt = [], [], [], []\nIDF_dict = Counter()\nit = 0\ncsv = pd.read_csv('../input/training.1600000.processed.noemoticon.csv', encoding = \"ISO-8859-1\", header=None)\n\ndef process_row(row, x, y):\n    sent = row[5]\n    x_part = sent.lower().split(' ')\n    #if len(x_part) < 12:\n    #    x_part = x_part + x_part\n    y_part = row[0]\n    for tok in x_part:\n        IDF_dict[tok] += 1\n    x.append(x_part)\n    if y_part == 0:\n        yy = np.array([0])\n    elif y_part == 4:\n        yy = np.array([1])\n    else:\n        raise Exception('Invalid y_part value=' + y_part)\n    y.append(yy)\n\n\nfor index, row in csv.iterrows():\n    if not it%21 == 0: # TRAINING\n        process_row(row, X, Y)\n\n    else:               # TEST\n        process_row(row, Xt, Yt)\n\n    it += 1\n\ndel csv",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9f23d92387ca3bf2fdbd96537a1048e26f4d8151"
      },
      "cell_type": "code",
      "source": "print('build words frequency map')\n\nmax_features = 50000\nwords_map = {}\nfor index, (word, freq) in enumerate(IDF_dict.most_common(max_features)):\n    words_map[word] = index + 1\nwords_map[''] = 0 # to be 100% sure that empty string encoded as 0",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "381f22412511f3d4d2c6bb0c576b64bc19ee08a9"
      },
      "cell_type": "code",
      "source": "print('encode input sequences')\n\ndef map_words(x):\n    maxlen = 0\n    for words in x:\n        for index, word in enumerate(words):\n            if word in words_map:\n                words[index] = words_map[word]\n            else:\n                words[index] = 0\n        words.append(0)\n        maxlen = max(maxlen, len(words))\n    return maxlen\n        \n\nmaxlen = map_words(X)\nmaxlen = max(maxlen, map_words(Xt))\nX = sequence.pad_sequences(X, padding='post', truncating='post', value=0, maxlen=maxlen)\nXt = sequence.pad_sequences(Xt, padding='post', truncating='post', value=0, maxlen=maxlen)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "919bdd957780d5ca32d1644588cd71e64cc4e297"
      },
      "cell_type": "code",
      "source": "print('build model')\n\nbatch_size = 32\n\nmodel = Sequential()\nmodel.add(Embedding(max_features, 128, input_length=maxlen))\nmodel.add(LSTM(64, return_sequences=True))\nmodel.add(LSTM(32))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\n# try using different optimizers and different optimizer configs\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\nprint(model.summary())\n\nprint('Train...')\nfor index in range(len(X)):\n    X[index] = np.array(X[index])\nfor index in range(len(Xt)):\n    Xt[index] = np.array(Xt[index])\nX = np.array(X)\nXt = np.array(Xt)\nY = np.array(Y)\nYt = np.array(Yt)\n\nmodel.fit(X, Y, batch_size=batch_size, epochs=1,validation_data=(Xt, Yt))\n\n\n\n\nscore, acc = model.evaluate(Xt, Yt,\n                            batch_size=batch_size)\nprint('Test score:', score)\nprint('Test accuracy:', acc)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "00d1b425264b838a499a26e2fa2bde37f72c49b3"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}