{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(datasets.FashionMNIST('data-fashion', train=True, \n",
    "                                                          download=True, \n",
    "                                                          transform=transforms.ToTensor()), \n",
    "                                                       batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(datasets.FashionMNIST('data-fashion', train=False, \n",
    "                                                          download=True, \n",
    "                                                          transform=transforms.ToTensor()), \n",
    "                                                       batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        # Hout = 1 + (Hin+2×padding[0]−dilation[0]×(kernel_size[0]−1)−1)/stride[0]\n",
    "        self.conv = nn.Sequential(\n",
    "            # shape = (batch_size, 1, 28, 28)\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            # shape = (batch_size, 16, 24, 24)\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            # shape = (batch_size, 16, 12, 12)\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            # shape = (batch_size, 32, 8, 8),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            # shape = (batch_size, 32, 4, 4)\n",
    "            nn.Dropout(p=0.2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            # (32, 4, 4) -> (512) -> (10)\n",
    "            nn.Linear(32* 4 * 4, 256),\n",
    "            nn.Linear(256, 10),\n",
    "            nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.conv(x)\n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    loss_f = torch.nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    tot_loss = 0\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_f(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tot_loss += loss\n",
    "    print('loss', batch_size * tot_loss.item() / len(train_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += data.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    print('accuracy', 100 * correct / total )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.48859232584635415\n",
      "accuracy 85.51\n",
      "loss 0.36134404500325523\n",
      "accuracy 86.52\n",
      "loss 0.3276580556233724\n",
      "accuracy 88.91\n",
      "loss 0.3037409210205078\n",
      "accuracy 85.26\n",
      "loss 0.2882270304361979\n",
      "accuracy 89.12\n",
      "loss 0.2768098704020182\n",
      "accuracy 89.41\n",
      "loss 0.2681060791015625\n",
      "accuracy 89.64\n",
      "loss 0.2606243133544922\n",
      "accuracy 89.39\n",
      "loss 0.25417762756347656\n",
      "accuracy 88.47\n",
      "loss 0.24833569844563802\n",
      "accuracy 90.3\n",
      "loss 0.24294230143229167\n",
      "accuracy 89.77\n",
      "loss 0.23860209147135417\n",
      "accuracy 88.33\n",
      "loss 0.23364082336425782\n",
      "accuracy 90.08\n",
      "loss 0.22904820760091146\n",
      "accuracy 90.49\n",
      "loss 0.22564737955729167\n",
      "accuracy 90.41\n",
      "loss 0.22026178995768228\n",
      "accuracy 90.17\n",
      "loss 0.21675916035970053\n",
      "accuracy 90.84\n",
      "loss 0.21449905395507812\n",
      "accuracy 89.03\n",
      "loss 0.21254071553548176\n",
      "accuracy 90.08\n",
      "loss 0.20710435231526692\n",
      "accuracy 90.1\n",
      "loss 0.20669217427571615\n",
      "accuracy 90.53\n",
      "loss 0.2010430908203125\n",
      "accuracy 90.84\n",
      "loss 0.20242870330810547\n",
      "accuracy 91.01\n",
      "loss 0.2007204818725586\n",
      "accuracy 90.91\n",
      "loss 0.1983448537190755\n",
      "accuracy 89.97\n",
      "loss 0.1946187973022461\n",
      "accuracy 90.82\n",
      "loss 0.1959929402669271\n",
      "accuracy 91.08\n",
      "loss 0.19130783081054686\n",
      "accuracy 89.31\n",
      "loss 0.18875911712646484\n",
      "accuracy 91.07\n",
      "loss 0.18754648844401042\n",
      "accuracy 90.02\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    train(model, train_loader, optimizer)\n",
    "    test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
